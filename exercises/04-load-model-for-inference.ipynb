{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading model from MLflow for inference ‚¨áÔ∏è\n",
    "\n",
    "By now, we have trained a model (or models) and wrote it to MLflow. \n",
    "\n",
    "Since our MLflow server is accessible over the internet, we can now load our model from anywhere. üåê <br>\n",
    "This is particularly useful when we want to deploy an application later on, which relies on our model. <br>\n",
    "But for now, let's look at how we can load our model back into this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we first need to connect to the server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://20.4.198.104:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our production model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = \"production\"\n",
    "model_name = \"turbine-model\"  # or choose the name you have given your model in the previous notebook \n",
    "\n",
    "model = mlflow.sklearn.load_model(f\"models:/{model_name}/{stage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And apply it to some data!\n",
    "\n",
    "But... which features did this model use? <br>\n",
    "We need to know these to pass the right data through the model. <br>\n",
    "Let's write use a function to load the model's features used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names(model_name: str, stage: str):\n",
    "    \"\"\"Get the feature names from the model metadata, given its name and stage.\"\"\"\n",
    "    \n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    model_version = client.get_latest_versions(name=model_name, stages=[stage])[0]\n",
    "    run_id = model_version.run_id\n",
    "    run = client.get_run(run_id)\n",
    "    features = run.data.params[\"features\"]\n",
    "    return features.split(\", \")\n",
    "\n",
    "features = get_feature_names(model_name, stage)\n",
    "print(f\"Features used by '{model_name}' in '{stage}':\\n {features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now apply it to some data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/turbine-data.csv\"\n",
    "data = pd.read_csv(data_path).set_index(\"timestamp\")\n",
    "data.index = pd.to_datetime(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_na = data.dropna()\n",
    "\n",
    "X = data_without_na[features]  # Exercise: what goes in the brackets?  \n",
    "y = data_without_na[\"active_power\"]\n",
    "\n",
    "data.loc[X.index, \"predictions\"] = model.predict(X)\n",
    "\n",
    "# Evaluate\n",
    "score = model.score(X, y)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_start = pd.Timestamp(\"2018-12-15\")\n",
    "fig = px.line(\n",
    "    data[plot_start:],\n",
    "    y=[\"active_power\", \"predictions\"]\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And why not log it back to MLflow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_metric(\"R2_score\", score)\n",
    "mlflow.log_figure(fig, \"predictions.html\")\n",
    "\n",
    "# Can you see it in the UI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packaging our solutions üì¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize: we now have trained a model locally, logged it to MLflow, and loaded it again for inference. üéâ <br>\n",
    "So far, however, all of this was done in a notebook. Unfortunaly, many ML projects with great potential get stuck in this phase.\n",
    "\n",
    "The question now is:\n",
    "- How do we turn our so-far notebook solution into a production-ready *application*? One that other people could use?\n",
    "\n",
    "In terms of usability, we are doing quite well already, as we have logged our model to MLflow. <br>\n",
    "However, we cannot expect everyone to know how to open a notebook, load our model, and get the predictions they want.\n",
    "\n",
    "From now on, we will therefore structure our code in python files, inside a package that others can *install*.\n",
    "Furthermore, we will create a RestAPI that allows others to send data to our model and get predictions back.\n",
    "\n",
    "Have a look at the `/turbine_power` folder, and inspect the inference code, which includes the same logic as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have already installed our own package during setup, we can also run it here:\n",
    "\n",
    "from turbine_power.inference import run_inference\n",
    "\n",
    "run_inference()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
