{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training ðŸ› \n",
    "\n",
    "Let's create a model that can predict the generated power, given the wind speed.\n",
    "In this notebook we use the package `scikit-learn` to prepare the data and train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly_express as px\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO PREP: store as CSV and update dependencies\n",
    "# We're in a new notebook, so we reload the data\n",
    "location = \"../data/turbine-data.csv\"\n",
    "data = pd.read_csv(location).set_index(\"timestamp\")\n",
    "data.index = pd.to_datetime(data.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some quick preparation of the data, before we train a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop data with missing values\n",
    "data_without_na = data.dropna() \n",
    "\n",
    "X = data_without_na[[\"wind_speed\"]]  # Our model's input\n",
    "y = data_without_na[\"active_power\"]  # Target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    shuffle=False,\n",
    "    # use (only) 10% of all data for training\n",
    "    train_size=0.1  # don't change this number\n",
    ")\n",
    "print(f\"Training data: from {X_train.index.min()} to {X_train.index.max()}\")\n",
    "print(f\"Testing data: from {X_test.index.min()} to {X_test.index.max()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create a model. Here we start small with a linear regression model. In the next notebook exercise you may make this model as fancy as you like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.pipeline.make_pipeline(\n",
    "    sklearn.linear_model.LinearRegression(),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.score(X_test, y_test)\n",
    "# score = model.score(X_train, y_train)\n",
    "score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good! <br>\n",
    "Or... is it?\n",
    "\n",
    "First of all, what does `score()` actually compute? You can use the following code cell to find out. What's better, a higher or lower score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??model.steps[-1][1].score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second of all, how do we know if this is *good* compared other runs for this dataset, or compared to the models of your neighbours?\n",
    "\n",
    "Let's find out how we can track these experiments better in the next excercise, and learn how experiment tracking improves the MLOps workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
